{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine tanslation using word level seq2seq model.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OptaOo0M1bV7",
        "colab_type": "text"
      },
      "source": [
        "Tutorial and code followed from here  -   https://mc.ai/neural-machine-translation-using-word-level-seq2seq-model/\n",
        "dataset can be downloaded from here -- https://github.com/devm2024/nmt_keras/blob/master/fra.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUbU5gxS1ofY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul1WuHP51vvP",
        "colab_type": "code",
        "outputId": "d8f62f7a-323d-43e2-910c-2da29a7a1b6c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-378765a7-aeb6-486d-9df3-8099d2c8d4b0\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-378765a7-aeb6-486d-9df3-8099d2c8d4b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving fra.txt to fra.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKWwGTB_1o4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCOl29Ld1bV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "# Building a english to french translator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "035jeGtG1bWG",
        "colab_type": "code",
        "outputId": "d688a1de-8dd6-4610-f094-43ddec67e6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "#changes the width of cells\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUL_vuj01bWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df= pd.read_csv('fra.txt',sep = '\\t',names=['eng','fr'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We6z5TQr1bWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfcopy = copy.copy(df)\n",
        "#taking only 1000 as I just need to understand how it's working , for actual implementation use complete dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n75UCouO1bWT",
        "colab_type": "code",
        "outputId": "b0f5c70c-8068-425e-8302-1dd75cc9ab6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape\n",
        "#eng and fr columns\n",
        "df.head()\n",
        "len(df)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk5rbcs-1bWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()\n",
        "df.iloc[11705]\n",
        "df = df[:20000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEE1yEkU1bWa",
        "colab_type": "code",
        "outputId": "b24d0ba9-28a5-4d5e-a176-771974f765d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "df.sample()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15766</th>\n",
              "      <td>You're all alone.</td>\n",
              "      <td>Vous êtes tout seul.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     eng                    fr\n",
              "15766  You're all alone.  Vous êtes tout seul."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ0Kwl9L1bWd",
        "colab_type": "code",
        "outputId": "55b3ef52-7ab1-47f5-be87-433543195003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>Au feu !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     eng          fr\n",
              "0    Go.        Va !\n",
              "1   Run!     Cours !\n",
              "2   Run!    Courez !\n",
              "3   Wow!  Ça alors !\n",
              "4  Fire!    Au feu !"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1QF5akx1bWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.eng=df.eng.apply(lambda x: x.lower())\n",
        "df.fr=df.fr.apply(lambda x: x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyf7SH2h1bWj",
        "colab_type": "code",
        "outputId": "d8ea630d-bce6-4955-f502-3a345f929776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go.</td>\n",
              "      <td>va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run!</td>\n",
              "      <td>cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run!</td>\n",
              "      <td>courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wow!</td>\n",
              "      <td>ça alors !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fire!</td>\n",
              "      <td>au feu !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     eng          fr\n",
              "0    go.        va !\n",
              "1   run!     cours !\n",
              "2   run!    courez !\n",
              "3   wow!  ça alors !\n",
              "4  fire!    au feu !"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az5oCXo31bWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Take the length as 50\n",
        "df.eng=df.eng.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
        "df.fr=df.fr.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8obixR11bWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#punctuations\n",
        "exclude = set(string.punctuation)\n",
        "df.eng=df.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "df.fr=df.fr.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1HxdZU11bWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_digits = str.maketrans('', '', digits)\n",
        "df.eng=df.eng.apply(lambda x: x.translate(remove_digits))\n",
        "df.fr=df.fr.apply(lambda x: x.translate(remove_digits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzOHqWQA1bWx",
        "colab_type": "code",
        "outputId": "fd5d1cdf-c868-4de9-ff69-97cc25533271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "Syntax : maketrans(str1, str2, str3)\n",
        "\n",
        "Parameters :\n",
        "str1 : Specifies the list of characters that need to be replaced.\n",
        "str2 : Specifies the list of characters with which the characters need to be replaced.\n",
        "str3 : Specifies the list of characters that needs to be deleted.\n",
        "\n",
        "Returns : Returns the translation table which specifies the conversions that can be used by translate()\n",
        "'''"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSyntax : maketrans(str1, str2, str3)\\n\\nParameters :\\nstr1 : Specifies the list of characters that need to be replaced.\\nstr2 : Specifies the list of characters with which the characters need to be replaced.\\nstr3 : Specifies the list of characters that needs to be deleted.\\n\\nReturns : Returns the translation table which specifies the conversions that can be used by translate()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqhgw4zK1bW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hu1yomW1bW2",
        "colab_type": "code",
        "outputId": "78b49c2f-3572-4d4a-cc4f-aa1a15017be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.fr = df.fr.apply(lambda x : 'START_ '+ x + ' _END')\n",
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go</td>\n",
              "      <td>START_ va  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ cours  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ courez  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wow</td>\n",
              "      <td>START_ ça alors  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fire</td>\n",
              "      <td>START_ au feu  _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    eng                     fr\n",
              "0    go        START_ va  _END\n",
              "1   run     START_ cours  _END\n",
              "2   run    START_ courez  _END\n",
              "3   wow  START_ ça alors  _END\n",
              "4  fire    START_ au feu  _END"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nLcPd9m1bW7",
        "colab_type": "text"
      },
      "source": [
        "### post filteration part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQW9oVrq1bW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_eng_words=set()\n",
        "for eng in df.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "    \n",
        "all_french_words=set()\n",
        "for fr in df.fr:\n",
        "    for word in fr.split():\n",
        "        if word not in all_french_words:\n",
        "            all_french_words.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcPHQVOc1bW-",
        "colab_type": "code",
        "outputId": "61f8c9fe-e8c6-498d-bb81-da7e016053e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(all_eng_words))\n",
        "print(len(all_french_words))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3445\n",
            "7196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLE-YJSl1bXC",
        "colab_type": "code",
        "outputId": "d767a3b5-a8a1-43bb-e1a8-45084a4a060c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "fr_lenght_list=[]\n",
        "for l in df.fr:\n",
        "    fr_lenght_list.append(len(l.split(' ')))\n",
        "\n",
        "eng_lenght_list=[]\n",
        "for l in df.eng:\n",
        "    eng_lenght_list.append(len(l.split(' ')))\n",
        "print(np.max(fr_lenght_list))\n",
        "print(np.max(eng_lenght_list))\n",
        "max_fr = np.max(fr_lenght_list)\n",
        "max_eng = np.max(eng_lenght_list)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmO9lYcQ1bXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_french_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_french_words)\n",
        "# del all_eng_words, all_french_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zW0KmxK1bXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQTv3bpl1bXK",
        "colab_type": "code",
        "outputId": "6c8ffb12-3532-409f-cbd8-69f82545efa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df.fr)*58*num_decoder_tokens\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8347360000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3_PwZJ_1bXN",
        "colab_type": "text"
      },
      "source": [
        "encoder_input_data is a matrix of dimentions = no_of_sentences*max_sentence_length  \n",
        "\n",
        "\n",
        "decoder_input_data is a matrix of dimentions = no_of_sentences*max_sentence_length  \n",
        "\n",
        "decoder_target_data is a matrix of dimensions = no_of_sentences*max_sentence_length*no_of_distinct_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqsby6461bXN",
        "colab_type": "code",
        "outputId": "1d2ded0c-36aa-4b1f-8017-f20d0257402b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(df.fr),num_decoder_tokens)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000 7196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLCr_Dkx1bXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(df.eng),max_eng ),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(df.fr), max_fr),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(df.fr), max_fr, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ULyqoki1bXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(df.eng, df.fr)):\n",
        "    for t, word in enumerate(input_text.split()):\n",
        "        encoder_input_data[i, t] = input_token_index[word]\n",
        "    for t, word in enumerate(target_text.split()):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] = target_token_index[word]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ6t34gy1bXX",
        "colab_type": "text"
      },
      "source": [
        "## The model making part\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkjcFEsx1bXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 50\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh-Zlvx01bXZ",
        "colab_type": "text"
      },
      "source": [
        "<b>Encoder Model</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A-tnQr21bXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b4ad9e4d-688a-433f-bb1a-ad0de13e41fc"
      },
      "source": [
        "encoder_inputs = Input(shape = (None,))\n",
        "encoder_embeddings = Embedding(num_encoder_tokens,embedding_size)(encoder_inputs)\n",
        "E_LSTM = LSTM(50,return_state=True)\n",
        "encoder_output , hidden_state , memory_cell = E_LSTM(encoder_embeddings)\n",
        "encoder_states = [hidden_state,memory_cell]\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYccepu31bXe",
        "colab_type": "text"
      },
      "source": [
        "<b> Decoder Model </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhTg71x41bXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape = (None,))\n",
        "decoder_embeddings = Embedding(num_decoder_tokens,embedding_size)\n",
        "final_dex = decoder_embeddings(decoder_inputs)\n",
        "decoder_LSTM = LSTM(50,return_sequences=True,return_state=True)\n",
        "decoder_outputs ,_ , _ = decoder_LSTM(final_dex, initial_state = encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens,activation='softmax') # total no of unique words\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkDfrTB01bXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "5fc0a475-c17b-4132-be34-9d6668b3573c"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     172250      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 50)     359800      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50), (None,  20200       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 20200       embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 7196)   366996      lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 939,446\n",
            "Trainable params: 939,446\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvwVa2GK1bXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "b998481b-6f06-4235-8bf1-a81c6ddaf9b9"
      },
      "source": [
        "\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          validation_split=0.05)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 19000 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "19000/19000 [==============================] - 16s 840us/step - loss: 2.0014 - acc: 0.0709 - val_loss: 2.1141 - val_acc: 0.0714\n",
            "Epoch 2/20\n",
            "19000/19000 [==============================] - 12s 634us/step - loss: 1.7118 - acc: 0.0786 - val_loss: 2.0013 - val_acc: 0.0714\n",
            "Epoch 3/20\n",
            "19000/19000 [==============================] - 12s 645us/step - loss: 1.6041 - acc: 0.0884 - val_loss: 1.9226 - val_acc: 0.0764\n",
            "Epoch 4/20\n",
            "19000/19000 [==============================] - 12s 637us/step - loss: 1.5261 - acc: 0.0972 - val_loss: 1.8519 - val_acc: 0.0856\n",
            "Epoch 5/20\n",
            "19000/19000 [==============================] - 12s 640us/step - loss: 1.4682 - acc: 0.1026 - val_loss: 1.7951 - val_acc: 0.0923\n",
            "Epoch 6/20\n",
            "19000/19000 [==============================] - 12s 632us/step - loss: 1.4168 - acc: 0.1079 - val_loss: 1.7374 - val_acc: 0.1089\n",
            "Epoch 7/20\n",
            "19000/19000 [==============================] - 12s 632us/step - loss: 1.3680 - acc: 0.1145 - val_loss: 1.7015 - val_acc: 0.1148\n",
            "Epoch 8/20\n",
            "19000/19000 [==============================] - 12s 633us/step - loss: 1.3226 - acc: 0.1205 - val_loss: 1.6463 - val_acc: 0.1216\n",
            "Epoch 9/20\n",
            "19000/19000 [==============================] - 12s 635us/step - loss: 1.2813 - acc: 0.1264 - val_loss: 1.6120 - val_acc: 0.1297\n",
            "Epoch 10/20\n",
            "19000/19000 [==============================] - 12s 634us/step - loss: 1.2454 - acc: 0.1315 - val_loss: 1.5799 - val_acc: 0.1331\n",
            "Epoch 11/20\n",
            "19000/19000 [==============================] - 12s 636us/step - loss: 1.2130 - acc: 0.1356 - val_loss: 1.5618 - val_acc: 0.1366\n",
            "Epoch 12/20\n",
            "19000/19000 [==============================] - 12s 644us/step - loss: 1.1841 - acc: 0.1390 - val_loss: 1.5408 - val_acc: 0.1407\n",
            "Epoch 13/20\n",
            "19000/19000 [==============================] - 12s 632us/step - loss: 1.1578 - acc: 0.1420 - val_loss: 1.5125 - val_acc: 0.1443\n",
            "Epoch 14/20\n",
            "19000/19000 [==============================] - 12s 632us/step - loss: 1.1326 - acc: 0.1450 - val_loss: 1.5005 - val_acc: 0.1474\n",
            "Epoch 15/20\n",
            "19000/19000 [==============================] - 12s 636us/step - loss: 1.1088 - acc: 0.1480 - val_loss: 1.4809 - val_acc: 0.1484\n",
            "Epoch 16/20\n",
            "19000/19000 [==============================] - 12s 631us/step - loss: 1.0859 - acc: 0.1505 - val_loss: 1.4703 - val_acc: 0.1521\n",
            "Epoch 17/20\n",
            "19000/19000 [==============================] - 12s 633us/step - loss: 1.0651 - acc: 0.1529 - val_loss: 1.4514 - val_acc: 0.1556\n",
            "Epoch 18/20\n",
            "19000/19000 [==============================] - 12s 642us/step - loss: 1.0441 - acc: 0.1555 - val_loss: 1.4348 - val_acc: 0.1603\n",
            "Epoch 19/20\n",
            "19000/19000 [==============================] - 12s 638us/step - loss: 1.0237 - acc: 0.1582 - val_loss: 1.4265 - val_acc: 0.1605\n",
            "Epoch 20/20\n",
            "19000/19000 [==============================] - 12s 629us/step - loss: 1.0043 - acc: 0.1608 - val_loss: 1.4173 - val_acc: 0.1606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8caf0cb940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzt3VDUk1bXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "ea61492f-bdcd-4213-cef7-da7c8e836056"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 50)          172250    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 50), (None, 50),  20200     \n",
            "=================================================================\n",
            "Total params: 192,450\n",
            "Trainable params: 192,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r6r0qih1bXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " decoder_state_input_h = Input(shape=(50,))\n",
        "decoder_state_input_c = Input(shape=(50,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "final_dex2=decoder_embeddings(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_LSTM(final_dex2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCXFWWk8sEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def decode_sequence(input_seq):\n",
        "    #input_seq is  [[1607.   80. 3062.    0.    0.]] for 14077\n",
        "    print(\"input is \",input_seq)\n",
        "    \n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    print(\"state_value is \", states_value)\n",
        "    '''\n",
        "    state_value is  [array([[-0.7356597 , -0.9993317 , -0.8581535 ,  0.9991428 ,  0.86860234,\n",
        "        -0.88219815,  0.6262745 , -0.9992849 ,  0.9986833 ,  0.99975616,\n",
        "        -0.96406317, -0.8911646 , -0.93668246,  0.8071924 , -0.9070601 ,\n",
        "        -0.9983337 , -0.6851529 , -0.5785509 ,  0.9981099 , -0.45333877,\n",
        "        -0.9723586 , -0.92026615, -0.5631677 , -0.9855832 ,  0.53639436,\n",
        "         0.7567345 ,  0.8314614 ,  0.98461056, -0.02521831, -0.90126914,\n",
        "         0.9989688 ,  0.8336466 , -0.9887398 , -0.7309139 , -0.52631956,\n",
        "        -0.6803367 , -0.9744914 , -0.9639372 ,  0.8591712 , -0.07826253,\n",
        "         0.9617582 , -0.7269689 , -0.9957466 , -0.6216118 , -0.9720878 ,\n",
        "         0.89779437,  0.93081397, -0.9966131 ,  0.9854572 ,  0.9793006 ]],\n",
        "      dtype=float32), array([[-3.2502072 , -4.0018077 , -2.370447  ,  3.8773093 ,  3.6909149 ,\n",
        "        -3.2669096 ,  3.1789834 , -3.9679527 ,  3.662548  ,  4.506039  ,\n",
        "        -2.5889246 , -1.4275558 , -2.4326057 ,  1.1189184 , -3.5042324 ,\n",
        "        -3.5447226 , -3.0464299 , -2.1128592 ,  3.4816515 , -2.5415885 ,\n",
        "        -2.1338346 , -1.5907625 , -0.63746005, -2.462637  ,  4.776198  ,\n",
        "         3.2632422 ,  3.4211106 ,  2.429748  , -0.02522366, -1.4789395 ,\n",
        "         3.7848165 ,  1.8303449 , -2.5869899 , -0.9306867 , -0.8429435 ,\n",
        "        -2.9611928 , -2.174526  , -1.9987224 ,  1.2901706 , -0.0784229 ,\n",
        "         1.9688332 , -3.3909166 , -3.0755305 , -2.5341778 , -2.1288924 ,\n",
        "         1.4607303 ,  1.664449  , -3.1896398 ,  2.4582543 ,  2.2801971 ]],\n",
        "      dtype=float32)]\n",
        "      \n",
        "     ''' \n",
        "    \n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1)) \n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "    print(\"target_seq is \",target_seq[0,0] )\n",
        "    \n",
        "    #target_seq is  1.0\n",
        "\n",
        "    \n",
        "    \n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "      output_tokens, h, c = decoder_model.predict(\n",
        "          [target_seq] + states_value)\n",
        "      print(\"output_tokens is \", output_tokens)\n",
        "\n",
        "      # Sample a token\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      print(\"sampled_token_index is \",sampled_token_index)\n",
        "      sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "      decoded_sentence += ' '+sampled_char\n",
        "\n",
        "      print(\"decoded sentence is \",decoded_sentence)\n",
        "      # Exit condition: either hit max length\n",
        "      # or find stop character.\n",
        "      if sampled_char == '_END' or len(decoded_sentence) > 52 :\n",
        "        stop_condition = True\n",
        "\n",
        "      # Update the target sequence (of length 1).\n",
        "      target_seq = np.zeros((1,1))\n",
        "      target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "      # Update states\n",
        "      states_value = [h, c]\n",
        "      \n",
        "      '''\n",
        "    output_tokens is  [[[1.9580897e-04 1.4204055e-10 3.0356929e-05 ... 3.8483760e-12\n",
        "       1.3986213e-14 2.2031972e-09]]]\n",
        "    sampled_token_index is  929\n",
        "    decoded sentence is   cest\n",
        "    output_tokens is  [[[4.6192162e-04 9.7681152e-07 1.8441869e-04 ... 1.9450983e-06\n",
        "       1.9787763e-06 3.8920575e-06]]]\n",
        "    sampled_token_index is  6753\n",
        "    decoded sentence is   cest un\n",
        "    output_tokens is  [[[4.5321140e-05 9.9775898e-06 2.7055165e-04 ... 3.3116699e-04\n",
        "       7.6128467e-04 3.4273871e-05]]]\n",
        "    sampled_token_index is  4784\n",
        "    decoded sentence is   cest un peu\n",
        "    output_tokens is  [[[2.2299837e-03 3.8076034e-06 2.4568696e-02 ... 7.3837878e-06\n",
        "       6.9453758e-06 2.5249241e-05]]]\n",
        "    sampled_token_index is  1566\n",
        "    decoded sentence is   cest un peu de\n",
        "    output_tokens is  [[[7.1985596e-05 3.0220974e-06 2.2143837e-04 ... 2.4737383e-05\n",
        "       1.8406533e-04 3.3893932e-05]]]\n",
        "    sampled_token_index is  1131\n",
        "    decoded sentence is   cest un peu de colère\n",
        "    output_tokens is  [[[4.6538683e-03 9.3184195e-07 7.0089167e-01 ... 5.0056883e-07\n",
        "        2.9316115e-07 1.3825561e-05]]]\n",
        "    sampled_token_index is  2\n",
        "    decoded sentence is   cest un peu de colère _END\n",
        "    -\n",
        "    \n",
        "    \n",
        "    '''\n",
        "      \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0alYikt8-pS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "340b9c59-449d-4863-a559-29ca9cb99ded"
      },
      "source": [
        "for seq_index in [14077]:\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', df.eng[seq_index: seq_index + 1])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input is  [[1607.   80. 3062.    0.    0.]]\n",
            "state_value is  [array([[-0.7356597 , -0.9993317 , -0.8581535 ,  0.9991428 ,  0.86860234,\n",
            "        -0.88219815,  0.6262745 , -0.9992849 ,  0.9986833 ,  0.99975616,\n",
            "        -0.96406317, -0.8911646 , -0.93668246,  0.8071924 , -0.9070601 ,\n",
            "        -0.9983337 , -0.6851529 , -0.5785509 ,  0.9981099 , -0.45333877,\n",
            "        -0.9723586 , -0.92026615, -0.5631677 , -0.9855832 ,  0.53639436,\n",
            "         0.7567345 ,  0.8314614 ,  0.98461056, -0.02521831, -0.90126914,\n",
            "         0.9989688 ,  0.8336466 , -0.9887398 , -0.7309139 , -0.52631956,\n",
            "        -0.6803367 , -0.9744914 , -0.9639372 ,  0.8591712 , -0.07826253,\n",
            "         0.9617582 , -0.7269689 , -0.9957466 , -0.6216118 , -0.9720878 ,\n",
            "         0.89779437,  0.93081397, -0.9966131 ,  0.9854572 ,  0.9793006 ]],\n",
            "      dtype=float32), array([[-3.2502072 , -4.0018077 , -2.370447  ,  3.8773093 ,  3.6909149 ,\n",
            "        -3.2669096 ,  3.1789834 , -3.9679527 ,  3.662548  ,  4.506039  ,\n",
            "        -2.5889246 , -1.4275558 , -2.4326057 ,  1.1189184 , -3.5042324 ,\n",
            "        -3.5447226 , -3.0464299 , -2.1128592 ,  3.4816515 , -2.5415885 ,\n",
            "        -2.1338346 , -1.5907625 , -0.63746005, -2.462637  ,  4.776198  ,\n",
            "         3.2632422 ,  3.4211106 ,  2.429748  , -0.02522366, -1.4789395 ,\n",
            "         3.7848165 ,  1.8303449 , -2.5869899 , -0.9306867 , -0.8429435 ,\n",
            "        -2.9611928 , -2.174526  , -1.9987224 ,  1.2901706 , -0.0784229 ,\n",
            "         1.9688332 , -3.3909166 , -3.0755305 , -2.5341778 , -2.1288924 ,\n",
            "         1.4607303 ,  1.664449  , -3.1896398 ,  2.4582543 ,  2.2801971 ]],\n",
            "      dtype=float32)]\n",
            "target_seq is  1.0\n",
            "output_tokens is  [[[1.9580897e-04 1.4204055e-10 3.0356929e-05 ... 3.8483760e-12\n",
            "   1.3986213e-14 2.2031972e-09]]]\n",
            "sampled_token_index is  929\n",
            "decoded sentence is   cest\n",
            "output_tokens is  [[[4.6192162e-04 9.7681152e-07 1.8441869e-04 ... 1.9450983e-06\n",
            "   1.9787763e-06 3.8920575e-06]]]\n",
            "sampled_token_index is  6753\n",
            "decoded sentence is   cest un\n",
            "output_tokens is  [[[4.5321140e-05 9.9775898e-06 2.7055165e-04 ... 3.3116699e-04\n",
            "   7.6128467e-04 3.4273871e-05]]]\n",
            "sampled_token_index is  4784\n",
            "decoded sentence is   cest un peu\n",
            "output_tokens is  [[[2.2299837e-03 3.8076034e-06 2.4568696e-02 ... 7.3837878e-06\n",
            "   6.9453758e-06 2.5249241e-05]]]\n",
            "sampled_token_index is  1566\n",
            "decoded sentence is   cest un peu de\n",
            "output_tokens is  [[[7.1985596e-05 3.0220974e-06 2.2143837e-04 ... 2.4737383e-05\n",
            "   1.8406533e-04 3.3893932e-05]]]\n",
            "sampled_token_index is  1131\n",
            "decoded sentence is   cest un peu de colère\n",
            "output_tokens is  [[[4.6538683e-03 9.3184195e-07 7.0089167e-01 ... 5.0056883e-07\n",
            "   2.9316115e-07 1.3825561e-05]]]\n",
            "sampled_token_index is  2\n",
            "decoded sentence is   cest un peu de colère _END\n",
            "-\n",
            "Input sentence: 14077    its almost time\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  cest un peu de colère _END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_06ioMNd9Ec3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZmh_VVvKiuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}